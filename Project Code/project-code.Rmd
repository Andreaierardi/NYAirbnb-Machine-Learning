---
title: "Statistical Learning Project"
author: Andrea Ierardi
output: 
  pdf_document:
        latex_engine: xelatex
        keep_tex: true

---
pdf_document: default
html_document: default


# Libraries
```{r}

library(knitr)
library(ggplot2)
library(plotly)

library(tidyr)
library(dplyr)
library(png)
library(ggpubr)
library(tidyverse)
library(caTools)
library(caret)
library(tree)
library(MASS)

library(randomForest)
library(ranger)
library(tuneRanger)


library(keras)

library(formattable)

library(clustMixType)
library(cluster)
library(dendextend) 
library(readr)
library(Rtsne)

library(factoextra)
library(FactoMineR)


library(PCAmixdata)

```


# Dataset 
[Link here](https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data)


```{r}
ds = read.csv("AB_NYC_2019.csv")
```


# Data Inspection

```{r}
head(ds)
summary(ds)
```

```{r}
img <- readPNG("map.png")


map_ds = ggplot() + background_image(img)+ geom_point(data = ds,  aes(y=latitude,x = longitude, color = price)) 
map_ds

```


# Data cleaning 

## Check for NA and NULL values
```{r}

apply(ds,2,function(x) sum(is.na(x)))

```

## Variable selection

```{r}
dataset = ds  %>% dplyr::select(neighbourhood_group,latitude, longitude, room_type,price)

head(dataset)
```


## Variable scaling
```{r}

scale_data = function(df)
{
  df = df %>%filter( price >= 15  & price <= 500)
  
  numerical = c("price")
  categorical = c("room_type", "neighbourhood_group")
  
  for( cat in categorical )
  {
    df[cat] = factor(df[[cat]], 
                     level = unique(df[[cat]]), 
                     labels = c(1:length(unique(df[[cat]])) ))
  }
  
  df[numerical] = as.numeric(scale(df[numerical]))
  return(df)
  
  
}
dataset = scale_data(dataset)

head(dataset)
summary(dataset)
```

## Data visualisation after the scaling
```{r}

mappa = ggplot() + background_image(img)+ geom_point(data = dataset,  aes(y=latitude,x = longitude, color = price)) 
mappa
```

# Data split 

## Split data in subsets for each neighbourhood_group and room_type
```{r}
neighbourhoods = unique(dataset$neighbourhood_group)

rooms = unique(dataset$room_type)


lis_n = vector("list")

for (n in neighbourhoods)
{
  tmp = dataset %>%filter( neighbourhood_group == n) 
  lis_n[[n]] = tmp[-1]
  
}



lis_r_n= vector("list")
for (n in neighbourhoods)
{
  for(r in rooms)
  {
    tmp = dataset %>%
      filter( room_type == r  & neighbourhood_group == n) 
    lis_r_n[[paste0("n",n,"-","r",r)]]= tmp[-1][-3]
    
  }
}


```


## SPlit in train and test for each subset
```{r}

trains = vector("list")
tests = vector("list")
datas = vector("list")

for (i in names(lis_n))
{
  sample = sample.split(lis_n[[i]], SplitRatio = .75)
  train = subset(lis_n[[i]], sample == TRUE)
  test  = subset(lis_n[[i]], sample == FALSE)
  trains[[i]]=  train
  tests[[i]] = test
  datas[[i]] = lis_n[[i]]
}

for (i in names(lis_r_n))
{
  sample = sample.split(lis_r_n[[i]], SplitRatio = .75)
  train = subset(lis_r_n[[i]], sample == TRUE)
  test  = subset(lis_r_n[[i]], sample == FALSE)
  trains[[i]]=  train
  tests[[i]] = test
  datas[[i]] = lis_r_n[[i]]
  
}

sample = sample.split(dataset, SplitRatio = .75)
train = subset(dataset, sample == TRUE)
test  = subset(dataset, sample == FALSE)

trains[["all"]] = train
tests[["all"]] = test
datas[["all"]] = dataset

```

# MODELS TRAIN

```{r}
model_lis = vector("list")
```
## LINEAR REGRESSION

```{r}

lin_reg = vector("list")

for (sub in names(trains))
{
  lin_reg[[sub]]$fit =lm.fit = lm(price~., data = trains[[sub]])
  lin_reg[[sub]]$summary = summary(lm.fit)
  
  lin_reg[[sub]]$pred  = pr.lm = predict(lm.fit,tests[[sub]])
  
  lin_reg[[sub]]$MSE = sum((pr.lm - tests[[sub]]$price)^2)/nrow(tests[[sub]])
  #lin_reg[[sub]]$plt=   plot(lm.fit)
}

lin_reg$name = "Linear Regression"
model_lis$linear_regression=  lin_reg
```


## DECISION  TREE

```{r}

dec_tree = vector("list")

for (sub in names(trains))
{
  dec_tree[[sub]]$fit = tree_res=tree(price~., data = trains[[sub]])
  dec_tree[[sub]]$summary = summary(tree_res)
  
  dec_tree[[sub]]$pred  = pred = predict(tree_res,tests[[sub]])
  
  dec_tree[[sub]]$MSE = sum((pred - tests[[sub]]$price)^2)/nrow(tests[[sub]])
  #dec_tree[[sub]]$plt=   plot(tree_res)+text(tree_res,pretty=0)
  
}

dec_tree$name = "Decision Tree"
model_lis$decision_tree = dec_tree
```


## RANDOM FOREST

```{r}

rf = vector("list")

for (sub in names(trains))
{
  rf[[sub]]$fit = res =  randomForest(  price ~ . , data=trains[[sub]])
  
  rf[[sub]]$pred = predt = predict(res,tests[[sub]])
  
  rf[[sub]]$MSE = sum((predt - tests[[sub]]$price)^2)/nrow(tests[[sub]])
}

rf$name = "Random Forest"
model_lis$random_forest = rf

```

## RANGER RANDOM FOREST

```{r}

ranger_rf = vector("list")

for (sub in names(trains))
{
  
  ranger_rf[[sub]]$fit = res = ranger( price~ ., data = trains[[sub]], write.forest = TRUE, classification = F)
  
  ranger_rf[[sub]]$pred = predt = predict(res,tests[[sub]])
  ranger_rf[[sub]]$MSE = sum((predt$predictions - tests[[sub]]$price)^2)/nrow(tests[[sub]])
  
  
  
}

ranger_rf$name = "Ranger Random Forest"
model_lis$ranger = ranger_rf


```


## NEURAL NETWORKS

```{r}
build_model <- function(dimension) {
  
  model <- keras::keras_model_sequential() %>%
    layer_dense(units = 32, activation = "relu",
                input_shape = dimension) %>%
    layer_dense(units = 16, activation = "relu") %>%
    layer_dense(units = 1,activation="linear")
  
  model %>% compile(
    loss = "mse",
    optimizer = optimizer_rmsprop(),
    metrics = list("mean_absolute_error")
  )
  
  return(model)
}


print_dot_callback <- callback_lambda(
  on_epoch_end = function(epoch, logs) {
    if (epoch %% 1 == 0) 
      cat(".")
  }
)    


nn = vector("list")

for (sub in names(trains))
{
  d = trains[[sub]]
  d2 = tests[[sub]]
  len = length(d)
  len2 = length(d2)
  
  if(!is.null(d$room_type))
  {
    d$room_type = keras::to_categorical(d$room_type)
    d2$room_type = keras::to_categorical(d2$room_type)
    
  }
  
  if(!is.null(d$neighbourhood_group)) 
  {
    d$neighbourhood_group = keras::to_categorical(d$neighbourhood_group)
    d2$neighbourhood_group = keras::to_categorical(d2$neighbourhood_group)
  }
  
  
  target = as.vector(d$price)
  features = as.matrix(as_tibble(d[-len]))
  
  target_test = as.vector(d2$price)
  features_test = as.matrix(as_tibble(d2[-len]))
  
  
  nn[[sub]]$epochs = epochs =  30
  
  nn[[sub]]$model = model =  build_model(dim(features)[2])
  
  nn[[sub]]$summary = model %>% summary()
  nn[[sub]]$history <- model %>% fit(
    x = features,
    y = target,
    epochs = epochs,
    validation_split = 0.2,
    verbose = 0,
    callbacks = list(print_dot_callback)
  )
  eva = model %>% evaluate(features_test,target_test, verbose = 0)
  
  nn[[sub]]$mae = eva[1]
  nn[[sub]]$loss = eva[2]
  
  nn[[sub]]$pred = pred = model %>% predict(features_test)
  nn[[sub]]$MSE = sum((pred - target_test)^2)/length(target_test)
  
}

nn$name = "Neural Networks"
model_lis$neural_networks = nn


```


# Comparison between the models
```{r}
concat = c()

for (n in unique(ds$neighbourhood_group))
{
  concat = c(concat,n) 
}
for (n in unique(ds$neighbourhood_group))
{
  for(r in unique(ds$room_type))
  {
    concat = c(concat, paste0(n,"/",r))
    
  }
}
concat = c(concat,"All")

n = names(nn)



cols = vector("list")
cols[["Subset"]] = concat
for( m in model_lis)
{
  col = c()
  for( nam in n)
  {
    
    if( nam != "name")
    { 
      col = c(col,m[[nam]]$MSE)  
      
    }
    
  }
  cols[[m$name]] = col
  
}
mse_df = as.data.frame(cols)
formattable(mse_df)
```






# Clustering and Groups

```{r}

data = datas

for(sub in names(data))
{
  data[[sub]]$latitude = scale(data[[sub]]$latitude)
  data[[sub]]$longitude = scale(data[[sub]]$longitude)
  
}
data

```

## Clustering for Mixed type of data
```{r}
library(clustMixType)
library(png)

library(ggpubr)

clust_num = 5

get_clusters = function(dts, num)
{
  l = list()
  if(is.null(dts$room_type))
  {
    l$cl = kmeans(dts,num)
  }
  else
  {
    l$cl = kproto(dts,num)
    
  }
  
  clust = list()
  
  for (i in 1:num)
  {
    indexes = l$cl$cluster == i
    clust[[i]] = dts[indexes,]
  }
  
  min_lat =  min(data$all$latitude)
  max_lat = max(data$all$latitude)
  min_long = min(data$all$longitude)
  max_long= max(data$all$longitude)

  
  myplot= ggplot() +  background_image(img)+  xlab('data_date') +  ylab('percent.change')+ theme(plot.margin = unit(c(1,1,1,1),"cm"),legend.title = element_text(colour="blue", size=10, face="bold")) + xlim(min_long, max_long) + ylim(min_lat,max_lat)
  
 
  count = 1
  l$clust_plot = vector("list")
  for(el in clust)
  {
    myplot = myplot+ geom_point(data = el, aes(y = latitude, x = longitude),color= count)
    
    p =ggplot()+geom_point(data = el, aes(y = latitude, x = longitude),color= count) + xlim(min_long, max_long) + ylim(min_lat,max_lat)
    
    l$clust_plot[[as.character(count)]] = p
    #print(paste0("=== clust: ",count,"==="))
    #print(summary(el))
    #print("=========")

    count= count+1
  }
  l$myplot = myplot
  return(l)
}

get_all_cluster = function(data, clust_num)
{
  lis = vector("list")
  for(sub in names(data))
  {
    
    lis[[sub]] = get_clusters(data[[sub]], clust_num)
    plot(lis[[sub]]$myplot)

  }
  return(lis)  
}

all_cluster = get_all_cluster(data,5)

#lis2 = get_clusters(datas,5)
#lis2$myplot


#lis3 = get_clusters(lis_r_n,5,F)
#lis3$myplot

```




# PCAmixdata

```{r}

## Import library
library(PCAmixdata)

```

```{r}

## Split mixed dataset into quantitative and qualitative variables
## For now excluding the target variable "Churn", which will be added later as a supplementary variable
#split <- splitmix(dataset[1:5])  
split = splitmix(dataset)
## PCA
res.pcamix <- PCAmix(X.quanti=split$X.quanti,  
                     X.quali=split$X.quali, 
                     rename.level=TRUE, 
                     graph=FALSE, 
                     ndim=25)

res.pcamix


```

```{r}

## Inspect principal components
res.pcamix$eig
```

```{r}

# Use Scree Diagram to select the components:
plot(res.pcamix$eig, type="b", main="Scree Diagram", xlab="Number of Component", ylab="Eigenvalues")
abline(h=1, lwd=3, col="red")
```





# Hierarchical Cluster Analysis

```{r}
agg = aggregate(price ~neighbourhood_group+room_type, dataset , mean)
agg

gower <- daisy(agg, metric = "gower")
hc1 <- hclust(gower, method = "complete" )

plot(hc1, cex = 0.6, hang = -1)


```

```{r}
library(dendextend)
avg_dend_obj <- as.dendrogram(hc1)
avg_col_dend <- color_branches(avg_dend_obj, h = 0.6)
plot(avg_col_dend)
```



```{r}
agg = aggregate(price ~neighbourhood_group, dataset , mean)
agg

rownames(agg) = c("Brooklyn","Manhattan",
                   "Queens","Staten Island", "Bronx")
agg$neighbourhood_group = NULL
gower <- daisy(agg, metric = "gower")
hc1 <- hclust(gower, method = "complete" )

plot(hc1, cex = 0.6, hang = -1)

library(factoextra)
#clust <- cutree(hc1, k = 5)

#fviz_cluster(list(data = agg, cluster = clust))  ## from ‘factoextra’ package 




```




# ==========================================
DA VEDEREE



#  - Factor Analysis of Mixed Data (FAMD)

http://www.sthda.com/english/articles/31-principal-component-methods-in-r-practical-guide/115-famd-factor-analysis-of-mixed-data-in-r-essentials/
https://nextjournal.com/pc-methods/calculate-pc-mixed-data
https://cran.r-project.org/web/packages/FactoMineR/index.html
https://stats.stackexchange.com/questions/5774/can-principal-component-analysis-be-applied-to-datasets-containing-a-mix-of-cont

```{r}

library("FactoMineR")
library("factoextra")
```

FAMD (base, ncp = 5, sup.var = NULL, ind.sup = NULL, graph = TRUE)
- base : a data frame with n rows (individuals) and p columns (variables).
- ncp: the number of dimensions kept in the results (by default 5)
- sup.var: a vector indicating the indexes of the supplementary variables.
- ind.sup: a vector indicating the indexes of the supplementary individuals.
- graph : a logical value. If TRUE a graph is displayed.

```{r}

res.famd <- FAMD(dataset, graph = FALSE, ncp = 10)
print(res.famd)
```


```{r}
eig.val <- get_eigenvalue(res.famd)
head(eig.val)

fviz_screeplot(res.famd)

```

```{r}
var <- get_famd_var(res.famd)
var
```

```{r}
# Coordinates of variables
head(var$coord)
# Cos2: quality of representation on the factore map
head(var$cos2)
# Contributions to the  dimensions
head(var$contrib)
```

```{r}
# Plot of variables
fviz_famd_var(res.famd, repel = TRUE)
# Contribution to the first dimension
fviz_contrib(res.famd, "var", axes = 1)
# Contribution to the second dimension
fviz_contrib(res.famd, "var", axes = 2)
# Contribution to the third dimension
fviz_contrib(res.famd, "var", axes = 3)
# Contribution to the forth dimension
fviz_contrib(res.famd, "var", axes = 4)
# Contribution to the fifth dimension
fviz_contrib(res.famd, "var", axes = 5)
# Contribution to the sixth dimension
fviz_contrib(res.famd, "var", axes = 6)
# Contribution to the seventh dimension
fviz_contrib(res.famd, "var", axes = 7)
# Contribution to the eighth dimension
fviz_contrib(res.famd, "var", axes = 8)
```