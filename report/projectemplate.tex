\documentclass{FR16} 
\usepackage{listings}
\usepackage{pdfpages}
\usepackage{subfiles} 
\usepackage{graphicx}

\begin{document}

\maketitle

% ML template reports
% https://www.cs.utexas.edu/~mooney/cs391L/paper-template.html
%https://github.com/udacity/machine-learning/blob/master/projects/capstone/report-example-1.pdf
\newpage
\tableofcontents
\newpage
\listoffigures
\newpage
\section{Abstract}
The aim of the project is to analyse, develop prediction models and define data clusters from the "New York City Airbnb Open Data" from a Kaggle competition.
\\ In particular, one part is focused on the development of predictive models to forecast house prices using these Supervised Learning technics:\begin{itemize}
\itemsep0em 
\item Linear Regression
\item Decision Tree
\item Random Forest
\item Ranger Random Forest
\item Neural Newtworks
\end{itemize}
For each of these, a comparison between the Mean Square Error and between all $R^2$ measure of all methods has been made to highlight which have the best performance. Also, for training all the models, a partition of the dataset in three parts has been applied: entire dataset, filtered by neighboorhood group and filtered for neighboorhood group and room type. In this way, it is possible to check the perfomance giving less or more features in input.\\\\
The second part is focused on the cluster and data reduction technics using these Unsupervised Learning technics:
\begin{itemize}
\itemsep0em
\item K-means Algorithm 
\item Clustering for mixed-type data
\item Principal Component Analysis
\end{itemize}

%%Eachreport must contain:\\
%•shortabstract: what are your going to present %in the report\\
%•statementof the problem/goalof the analysis %and description of thedata set(s)\\
%•list of three to fivefindings/keypoints\\
%•the analysis with wisecommentary\\
%•(optional) theoretical background of the used %methods\\
%•conclusions(should include the findings/%keypoints)\\
%•theAppendix, containing all the R codeNotice:
%\\•Thepaper lengthisirrelevant provided that %the content is correct.
%\\•No R code in the main text.The R code must %be confined to the appendix\\
%•The report should be prepared inPDFonly

\newpage
\section{Problem Definition and Algorithm}
\subsection{Two main Goals}

\subsubsection{Develop predictive models for price}
The first objective is the forecast of the prices given some input information. This could be usefull for a lot of scenarios. For example from a AirBnB customer point of view, he/she would like to get the list of houses more in alignment with his/her preference choice; or for a host point of view, where given the position and other information he/she could get information about the possible per day price of his property in New York City. 

\subsubsection{Define clusters and groups}
The second objective is the definition of group or partition between the houses with different characteristics. For a user point of view could be usefull to have information about avaiable houses similar to those booked in the past. This could be also usefull after the booking for a suggestion analysis having the information about last booked houses in NewYork or houses in similar cities around the world.
\newpage
\subsection{Algorithms}
\subsubsection{Linear Regression}
 Linear regression  is a linear approach to modeling the relationship between a dependent variable and one or more independent variables. 
 
  \subsubsection{Decison Trees}
In decision analysis, a decision tree can be used to visually and explicitly represent decisions and decision making.

 \subsubsection{Random Forest}
 Random forests are an ensemble learning method for classification, regression and other tasks that operate by constructing a multitude of decision trees.
 \subsubsection{Ranger Random Forest}
Ranger is a fast implementation of random forests or recursive partitioning, particularly suited for high dimensional data. 

\subsubsection{Neural Networks}
Neural networks are a set of algorithms, modeled loosely after the human brain, that are designed to recognize patterns.

\subsubsection{K-means}
K-means is a method of vector quantization, originally from signal processing, that aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean.

\subsubsection{Principal Component Analysis}
Principal Component Analysis (PCA) is mostly used as a tool in exploratory data analysis and for making predictive models.

\newpage
\section{Experimental Evaluation}

\subsection{Methodology}
\subsubsection{Data Inspection}
The dataset is part of a Kaggle competition, called the New York City Airbnb Open Data. It contains 48.000 rows per 16 columns.
The dataset is structured with these columns: 
\begin{itemize}
\itemsep0em 
\item \textbf{id}
\item \textbf{name}: name of the listing
\item \textbf{host\_id}
\item \textbf{host\_name}
\item \textbf{neighbourhood\_group}: location
\item \textbf{neighbourhood}: area
\item \textbf{latitude}: coordinates
\item \textbf{longitude}: coordinates
\item \textbf{room\_type}: space type
\item \textbf{price}:  in dollars
\item \textbf{minimum\_nights}: amount of nights minimum
\item \textbf{number\_of\_reviews}: number of reviews
\item \textbf{last\_review}: latest review
\item \textbf{reviews\_per\_month}: number of reviews per month
\item \textbf{calculated\_host\_listings\_count}: amount of listing per host
\item  \textbf{availability\_365}: number of days when listing is available for booking\\
\end{itemize}
It has been select only 5 of these variables: price, latitude, longitude, neighbourhood\_group and room\_type. The reason is that it is reasonable to select them to predict the prices and to obtain different clusters. The position and the neighbourhood is important since if a property is positioned near the city center will have a higher price with respect to those situated in the outskirts; also the type of room, since an entire apartment will cost more than a single room. \\\\
From the Figure \ref{fig:1} is possible to see the distribution of the price. The minimum price is $0$ and the maximum is $10000\$$. It is not possible to rent a house for free, so it is possible to filter the price with a price higher than $15\$$. It is possible that a luxury house cost a lot per day, but these value can not be consider in the model, instead they are outliers and for this reason it is convenient to filter the price again and take those that have a value lowert than $500\$$. The reason is that the third quantile has a price of $175\$$ which is a far from $10000\$$ (Figure \ref{fig:3}). It has also been checked the null and missing value  in the dataset and has not been found apart from the reviews\_per\_month column. It is not a problem, since this feature has been not taken in account to train the models. 
\\
\begin{figure}[H]
\centering
\includegraphics[width=0.3\textwidth]{figures/figure1.jpg} 
\caption{\label{fig:1}Price summary}
\end{figure}
\noindent From Figure \ref{fig:2}, it is possible to see the distribution of all houses in New York City and the price. This picture is not really informative since it can be noticed that the prices for the most part are in the range $0$-$500\$$ and only a low number of istances have a price greater than $500\$$. Deleting the outliers, the Figure \ref{fig:3} is more informative than the one before.

\begin{figure}[H]
\centering
\includegraphics[width=0.5\textwidth]{figures/figure2.pdf} 
\caption{\label{fig:2}Distribution of all houses in NY colored by prices}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.5\textwidth]{figures/figure3.pdf} 
\caption{\label{fig:3} Distribution of all houses in NY of price between $15\$$ and $500\$$ per day}
\end{figure}
\subsubsection{Data Cleaning and Pre-processing}

The dataset has approximately 48.000 rows for each column, so an important part of the work is related to the pre-processing due to the large amount of data. For this reason, some variable has been rescaled to let the models to learn faster and better and to perform a better prediction. Latitude and longitude have not been rescaled for forecast price model, while for clustering methods to have a consistent distance calculation. Categorical variables have also been rescaled assigning a numerical value to each category, resulting as unordered factors.\\
The selected categorical variables are: neighbourhood\_group and room type.\\
The selected numerical variables are: latitude, longitude and price.
\\\\
Considering that every neighbourhood group has his characteristic, also taking in account the room type that could impact largerly the price. It is possible to define of different subset of the original set and try different methods of forecast. This is due to the fact that a customer should choose which of the different neighbourhood and room type is interested in. Models have been run to different scenarios (Figure \ref{fig:4}): users interested in all New York City houses and all type of room, users interested only in a single neighbourhood and users interested in a single neighbourhood and a single room type. 
\\ Including different scenario could be potentially computationally expensive. In reality, the training proceeded without any problem. \footnote{ The models have been trained on a machine with quad-core 3.5 GHz processor, 8 Gb RAM and 4 Gb dedicated GPU.} Computantional problem may emerge for the case of hyperparametrisation tuning, even using multiprocessing and multithreading technics. For semplicity, in this project no model tuning have been made. \\
Also for clustering have been filter every scenario, but not for the case of Hierarchical Clustering because it need to generate a readable dendogram using the mean of all neighbourhood or room type price, Principal Component Analysis since avaiable data are really small for some specific neighbourhood like Staten Island and specific room type.


\begin{figure}[H]
\centering
\includegraphics[width=0.5\textwidth]{figures/figure4.PNG} 
\caption{\label{fig:4}  Approximated distribution map of all houses in Manhattan }
\end{figure}



\subsection{Results}

Since the number of models trained are very high, the study result will be presented for different macro groups that depend on the different subset of the dataset: entire dataset,  filtering by neighborhood and filtering by neighborhood and room type. This is due to the fact that neighborhood in general have similar result (like Manhattan has similar shape of Brooklyn and Staten Island has a similar shape of Bronx).\\\\
 =====
 DA RIVEDERE
 ===\\
\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{figures/model_summary.PNG} 
\caption{\label{fig:5} Summary of the MSE for all the models for each subset of the dataset }
\end{figure}

\newpage
\subsubsection{Linear Regression Results}
%Linear Regression has been applied to the different subset and gains different results based on the macro group.

\textbf{Linear Regression on the entire dataset}\\
\noindent The results on the entire dataset are acceptable. All variables are significant for the model and the $R^2$ value is 40\% (Figure \ref{fig:6}).
The Mean Square Error (Figure \ref{fig:5}) has a value of 0.6 which is acceptable. All the neighboorhood groups have a positive effect on the price apart for the $4^th$ one. This could be due to the fact that Staten Island does not have expensive houses compared to the other group. \\
Also the latitude and longitude have a sligh negative effect on the price. Entire apartment have a slight positive effect while the shared house negative. This could be due to the fact that an entire house will cost more than a shared room, so the price will increase for this type of room. 

\begin{figure}[H]
\centering
\includegraphics[width=0.5\textwidth]{figures/lm1.PNG} 
\caption{\label{fig:6} Linear Regression output for the entire dataset}
\end{figure}
\noindent
\textbf{Linear Regression for specific Neighboorhood group}

\noindent Models give different results for the specific neighboorhood group. For the first three (Brooklyn, Manhattan and Queens) $R^2$ are over approximately 30\%. For the MSE, the value have different ranges based on the distribution of prices in the singolar neighboorhood. To be noticed, is the fact that MSE of Brooklyn is significantly lower with respect to Manhattan, given the have a similar number of houses and have almost the same price distribution. The only difference between the two is the fact that Manhattan has more entire apartment type of room. 
\\ All variables have a significant effect on the price apart for the latitude in Manhattan and longitude for Queens with a 0.1.  \\
For the last two groups (Staten Island and Bronx) all variables does not have significance in the response variable apart for the Entire Apartment dummy which have a positive effect. This is due to the fact that entire properties will cost more than shared rooms.
\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{figures/lm2.jpg} 
\caption{\label{fig:6}  Linear Regression output filtering by  Manhattan}
\end{figure}
\noindent \\\\  \textbf{Linear Regression for specific Neighboorhood group and room type}\\
\noindent Adding a filter also for the room type, models give acceptable results in some cases and not in others. (Figure \ref{fig:7}) 
For the larger subset the model confirm the significant of the variables, apart for latitude in Manhattan such as happened in the model using this neighboorhood data. In Manhattan with Entire apartment model, instead, all variables have a significant effect. For the remaining neighboorhood groups the variables do not result as significant in the model. This could be due to the fact that the subset obtained from this filtering are not large ( they have less than 300 rows). Also in all model the $R^2$ result to be lower than $10\%$ but this depends on the fact to train they have less information.
\\
Also in this model the MSE of Brooklyn is lower in all the type of room type than the Manhattan MSE. 
\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{figures/lm3.PNG} 
\caption{\label{fig:7}  Linear Regression output filtering by  Manhattan and Entire home/Apartment }
\end{figure}




\newpage 
\subsubsection{Decison Trees Results}
\textbf{Decison tree  without filters}\\
\noindent For the entire dataset the MSE has a value of $0.605$ (Figure \ref{fig:9}) Important to be notice is the fact that the neighboorhood group variable have not been used in the construction of the tree. Moreover, what really influence the price is the type of room (Figure \ref{fig:10}).


\begin{figure}[!htb]
   \begin{minipage}{0.48\textwidth}
     \centering
     \includegraphics[width=.7\linewidth]{figures/dt.PNG} 
     \caption{Decision Tree results on the entire dataset}\label{fig:9}
   \end{minipage}\hfill
   \begin{minipage}{0.48\textwidth}
     \centering
     \includegraphics[width=.7\linewidth]{figures/tree-all.PNG}
     \caption{Tree generated for the entire dataset}\label{fig:10}
   \end{minipage}
\end{figure}


\noindent \\ \textbf{Decison tree for specific Neighboorhood group}\\
\noindent For the specific neighboorhood group decision tree models give output similar MSE results with respect to the Linear Regression. Also in this case, the latitude for Manhattan has not been used in the model to predict the price (Figure \ref{fig:11}). 

\begin{figure}[!htb]
   \begin{minipage}{0.48\textwidth}
     \centering
     \includegraphics[width=.7\linewidth]{figures/dt1.1.PNG} 
   \end{minipage}\hfill
   \begin{minipage}{0.48\textwidth}
     \centering
     \includegraphics[width=.7\linewidth]{figures/dt1.2.PNG}
   \end{minipage}
        \caption{ Decision tree results for specific neighboorhood group}\label{fig:11}

\end{figure}

\newpage 
\noindent \textbf{Decison tree  for specific Neighboorhood group and room type}
 
\noindent For neighboorhood group and room price Decision tree construction was not possible for all the subset. For example for shared room for Bronx were not possible to plot the tree since the model had only one node. MSE are similar to Linear Regression but for this type of subset perform slighly worse. This is due to the lack of information of some of these subsets (Figure \ref{fig:12}).
\newpage
\begin{figure}[!htb]
   \begin{minipage}{0.48\textwidth}
     \centering
     \includegraphics[width=.7\linewidth]{figures/dt2.PNG} 
   \end{minipage}\hfill
   \begin{minipage}{0.48\textwidth}
     \centering
     \includegraphics[width=.7\linewidth]{figures/dt3.PNG}
   \end{minipage}
   
    \begin{minipage}{0.48\textwidth}
     \centering
     \includegraphics[width=.7\linewidth]{figures/dt4.1.PNG}
   \end{minipage}
   
   
    \begin{minipage}{0.48\textwidth}
     \centering
     \includegraphics[width=.7\linewidth]{figures/dt4.2.PNG}
   \end{minipage}
        \caption{ Decision tree results for specific neighboorhood group and room type}\label{fig:12}

\end{figure}

\newpage
\subsubsection{Random Forest Results}
There were no problem running Random Forest regression for the price, givin the default parameters. For the parameter tuning there were no possibilities for the entire dataset, due to the large number of data points. For the filtered dataset, instead, were possible to tune the mtry, number of maximum nodes and number of trees.
\\\\ \textbf{Random Forest  on the entire dataset}\\
There were no possibility to run a forecast of the price

\begin{figure}[h]
\centering
\includegraphics[width=0.7\textwidth]{figures/rf.PNG} 
 \caption{\label{fig:13} Random Forest results on the entire dataset}
\end{figure}

\noindent \textbf{Random Forest for specific Neighboorhood group}\\
\begin{figure}[!htb]
   \begin{minipage}{0.48\textwidth}
     \centering
     \includegraphics[width=.7\linewidth]{figures/rf1.1.png} 
   \end{minipage}\hfill
   \begin{minipage}{0.48\textwidth}
     \centering
     \includegraphics[width=.7\linewidth]{figures/rf1.2.png}
   \end{minipage}
        \caption{ Random Forest results for specific neighboorhood group}\label{fig:14}

\end{figure}

\noindent \textbf{Random Forest  for specific Neighboorhood group and room type}
Using the tuning of the parameter the results are slightly better. The model start with a $23\%$ explained variance to a value of $25\%$.

\begin{figure}[!htb]
   \begin{minipage}{0.33\textwidth}
     \centering
     \includegraphics[width=.8\linewidth]{figures/rf2.png} 
   \end{minipage}\hfill
   \begin{minipage}{0.33\textwidth}
     \centering
     \includegraphics[width=.8\linewidth]{figures/rf3.png}
   \end{minipage}
   \begin{minipage}{0.33\textwidth}
     \centering
     \includegraphics[width=.8\linewidth]{figures/rf4.png} 
   \end{minipage}\hfill
   \begin{minipage}{0.33\textwidth}
     \centering
     \includegraphics[width=.8\linewidth]{figures/rf5.png}
   \end{minipage}
   \begin{minipage}{0.33\textwidth}
     \centering
     \includegraphics[width=.8\linewidth]{figures/rf6.png}
   \end{minipage}
        \caption{ Random Forest results for specific neighboorhood group and room type}\label{fig:15}

\end{figure}

\newpage
\subsubsection{Ranger Random Forest Results}
Ranger Random Forest is known to be computationally light with respect to the classic Random Forest. In fact, for the tuning part there were not problem in running it for the entire dataset. 
\\\\ \textbf{Ranger on the entire dataset }\\
Ranger outputs for the entire dataset are consistent. We have a $R^2$ of 0.47 and OOB error of .
\\\\
\textbf{Ranger for specific Neighboorhood group}\\
\\\\ 
\textbf{Ranger for specific Neighboorhood group and room type}
The dataset filtered by neighboorhood and room type gives as result a $R^2$ of 0.25.
\\\\





\newpage
\subsubsection{Neural Network Results}
\textbf{Neural Networks on the entire dataset }\\

\textbf{Neural Networks for specific Neighboorhood group}\\
\\\\ 
\textbf{Neural Networks  for specific Neighboorhood group and room type}




\subsubsection{K-means Results}


\subsubsection{Principal Component Analysis Results}

\newpage
\subsection{Discussion}

\subsubsection{Linear Regression Discussion}
Linear regression model gives interesting results for the non-filtered dataset and also for the filtered by neighbourhood group.
All variable results to rejected by Null hyphotesis, so the model depends on all the selected variables.
Latitude and longitude are correlated with the target, room type is strongly positive correlated with the price and neighbourhood group does not seem to have
a great contribution in the prediction of the price.
\\

\subsubsection{Decision Tree Discussion}
The performance with respect to the other models are not the best, but acceptable. The predicton results are not also very precised for the filtered neighboorhood 
and room type. Also, the plots of the predicted value are not so consistent since the values are divided in category which correspond to the leaves that are not so strong
with respect to the other model predictions.
\\

\subsubsection{Random Forest Discussion}
Random forest outputs consistent results and performs  better than linear regression and decision tree. 
Parameters tuning does not give big improvement in performance and also are computationally expensive.
\\

\subsubsection{Ranger Random Forest Discussion}
Results of Ranger are the best with respect to the previous models. Also the tuning part was fast and computationally cheaper than 
the classic Random Forest model but does not give great improvements in performance.
\\
\subsubsection{Neural Network Discussion}
\subsubsection{K-Means Discussion}
\subsubsection{Principal Component Analysis Discussion}

\section{Conclusion}

From the result the method with the most higher accuracy is the Random Forest method... while the worst are ....
\\Moreover, Random Forest method is also the worst in term of computation time for the tuning part since it takes for a configuration with 4 core, more or less 1 hour to tune the parameters. 

\
\subsection{Linear Regression}


\subsection{Decision Tree}
Decision  tree are one of the most used model in the Machine Learning world since are very familiar to human users and can be easily plotted. 
\\



\subsection{Random Forest}
Random Forest is an ensemble method which use a combination of decision tree to get the prediction.
\subsubsection{Ranger Random Forest}
Ranger Random Forest is a computationally light model which results are very close the classical Random Forest.
\\





\newpage
\section{Appendix}
%\subfile{project}
The code is in the file "project-code.Rmd" and is attached to this file.

%\includepdf[pages=-, pagecommand=\thispagestyle{plain}]{project.tex}
%\noinden



\end{document}